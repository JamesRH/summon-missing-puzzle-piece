{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNfCQPD3UHjhrwEUzO0QQq8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Goal\n","\n","The purpose of the script is to take two images and align them. The first image is the correct dimensions and print socks and orientation. The second image should be resized and rotated to align to a subsection of the first. The second image will have damaged pixels and lines and different color balances. It will also have one area that is white and very different than the image around it. Using the watershed air better algorithms find the outlines of this white area and change all the pixels within the outline to the clear alpha channel.  Use libraries like OpenCV (cv2) and Pillow (PIL) to isolate the alpha channel as a mask, then calculate transformations based only on non-zero alpha areas so that the second image is rotated and resized to best line with the first image. Lastly, take all of the pixels of the first image That are now overlapping with the alpha outlined region and generate a output image with those pixels and a sharp dark outline. Save this as a PNG with all of the metadata such that it will print out at the correct original scale. Provide an option to save the intermediate aligned images In a format that allows multiple layers.\n","\n","This python script that can be used as a library, a command line tool, or a cross platform GUI with simple file loading dialogues."],"metadata":{"id":"lc_VnZUfA9iX"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2f6a9cac","executionInfo":{"status":"ok","timestamp":1771179535391,"user_tz":420,"elapsed":7789,"user":{"displayName":"James Henriksen","userId":"05845938552738523524"}},"outputId":"86dfd358-aad2-4de3-b077-c204372c6bd0"},"source":["pip install svgwrite"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: svgwrite in /usr/local/lib/python3.12/dist-packages (1.4.3)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ZCoZx3Oswxp6KMd8qYvKZCKo8aTBklwj"},"id":"6c0d3910","executionInfo":{"status":"ok","timestamp":1771179539024,"user_tz":420,"elapsed":3618,"user":{"displayName":"James Henriksen","userId":"05845938552738523524"}},"outputId":"f78cf3c8-7105-4fb7-a1cf-cbc547270cbd"},"source":["import cv2\n","import numpy as np\n","import os\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import svgwrite # Added for SVG output\n","\n","class ImageAligner:\n","    \"\"\"\n","    Library class for aligning images, isolating regions, and extracting composites.\n","    \"\"\"\n","    def __init__(self, debug=False, detector=None, matcher=None):\n","        self.debug = debug\n","\n","        # Initialize detector: SIFT as default as it worked well in tests\n","        if detector is None:\n","            self.detector = cv2.SIFT_create()\n","        else:\n","            self.detector = detector\n","\n","        # Initialize matcher: BFMatcher with NORM_L2 as default for SIFT\n","        if matcher is None:\n","            self.matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False) # crossCheck=False for knnMatch with ratio test\n","        else:\n","            self.matcher = matcher\n","\n","    def _find_white_region(self, img_bgra):\n","        \"\"\"\n","        Finds the largest white region, ignoring noise and damaged lines.\n","        Returns a binary mask of the white area.\n","        \"\"\"\n","        hsv = cv2.cvtColor(img_bgra, cv2.COLOR_BGRA2BGR)\n","        hsv = cv2.cvtColor(hsv, cv2.COLOR_BGR2HSV)\n","\n","        lower_white = np.array([0, 0, 200], dtype=np.uint8)\n","        upper_white = np.array([180, 50, 255], dtype=np.uint8)\n","        white_mask = cv2.inRange(hsv, lower_white, upper_white)\n","\n","        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n","        white_mask = cv2.morphologyEx(white_mask, cv2.MORPH_OPEN, kernel)\n","        white_mask = cv2.morphologyEx(white_mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n","\n","        contours, _ = cv2.findContours(white_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","        if not contours:\n","            raise ValueError(\"Could not find any white area in the second image.\")\n","\n","        largest_contour = max(contours, key=cv2.contourArea)\n","\n","        clean_mask = np.zeros_like(white_mask)\n","        cv2.drawContours(clean_mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n","\n","        return clean_mask\n","\n","    def _find_dark_lines_mask(self, img_bgra):\n","        \"\"\"\n","        Identifies continuous dark lines in a BGRA image and returns a binary mask.\n","        \"\"\"\n","        # Convert to grayscale\n","        gray = cv2.cvtColor(img_bgra, cv2.COLOR_BGRA2GRAY)\n","\n","        # Apply adaptive thresholding to identify dark regions\n","        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n","                                       cv2.THRESH_BINARY_INV, 11, 2)\n","\n","        # Define a kernel for morphological operations\n","        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n","\n","        # Apply closing to connect close dark regions\n","        closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n","        # Apply opening to remove small noisy areas\n","        opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel)\n","\n","        # Find contours\n","        contours, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","        # Create an empty mask to draw the significant dark lines\n","        dark_lines_mask = np.zeros_like(gray, dtype=np.uint8)\n","\n","        # Iterate through contours and filter by area, then draw\n","        min_contour_area = 50 # Adjust this value based on expected line thickness/size\n","        for contour in contours:\n","            if cv2.contourArea(contour) > min_contour_area:\n","                cv2.drawContours(dark_lines_mask, [contour], -1, 255, thickness=cv2.FILLED)\n","\n","        return dark_lines_mask\n","\n","    def process(self, complete_image_path, missing_image_path, output_path, save_intermediate=False, show_matches=False, draw_contours=False, save_svg_contour=False): # Added save_svg_contour\n","        \"\"\"\n","        Main pipeline function.\n","        \"\"\"\n","        complete_image = cv2.imread(complete_image_path, cv2.IMREAD_UNCHANGED)\n","        missing_image = cv2.imread(missing_image_path, cv2.IMREAD_UNCHANGED)\n","\n","        if complete_image is None or missing_image is None:\n","            raise FileNotFoundError(\"Could not load one or both input images. Check your file paths.\")\n","\n","        if complete_image.shape[2] == 3:\n","            complete_image = cv2.cvtColor(complete_image, cv2.COLOR_BGR2BGRA)\n","        if missing_image.shape[2] == 3:\n","            missing_image = cv2.cvtColor(missing_image, cv2.COLOR_BGR2BGRA)\n","\n","        if self.debug and show_matches:\n","            plt.figure(figsize=(20, 10))\n","\n","            plt.subplot(1, 2, 1)\n","            plt.imshow(cv2.cvtColor(complete_image, cv2.COLOR_BGRA2RGBA))\n","            plt.title(\"Complete Image (Original)\")\n","            plt.axis('off')\n","\n","            plt.subplot(1, 2, 2)\n","            plt.imshow(cv2.cvtColor(missing_image, cv2.COLOR_BGRA2RGBA))\n","            plt.title(\"Missing Image (Original)\")\n","            plt.axis('off')\n","            plt.show()\n","\n","        # Find white region in missing_image and make it transparent\n","        white_region_mask = self._find_white_region(missing_image)\n","        missing_image[white_region_mask == 255, 3] = 0\n","\n","        # Find dark lines in missing_image\n","        dark_lines_mask = self._find_dark_lines_mask(missing_image)\n","\n","        gray_complete_image = cv2.cvtColor(complete_image, cv2.COLOR_BGRA2GRAY)\n","        gray_missing_image = cv2.cvtColor(missing_image, cv2.COLOR_BGRA2GRAY)\n","\n","        # Create a valid mask for missing_image features: not transparent AND not dark lines\n","        valid_missing_image_mask = (missing_image[:, :, 3] > 0).astype(np.uint8) * 255\n","        valid_missing_image_mask = cv2.bitwise_and(valid_missing_image_mask, cv2.bitwise_not(dark_lines_mask))\n","\n","        # Feature detection\n","        kp_complete_image, des_complete_image = self.detector.detectAndCompute(gray_complete_image, None)\n","        kp_missing_image, des_missing_image = self.detector.detectAndCompute(gray_missing_image, mask=valid_missing_image_mask)\n","\n","        if self.debug:\n","            print(f\"Keypoints found in complete_image: {len(kp_complete_image) if kp_complete_image is not None else 0}\")\n","            print(f\"Keypoints found in missing_image (after masking): {len(kp_missing_image) if kp_missing_image is not None else 0}\")\n","\n","        if des_complete_image is None or des_missing_image is None or len(des_complete_image) < 4 or len(des_missing_image) < 4:\n","            raise ValueError(\"Not enough features found to align images. Check image content or mask parameters.\")\n","\n","        # Feature matching using knnMatch and ratio test\n","        matches = self.matcher.knnMatch(des_missing_image, des_complete_image, k=2)\n","\n","        good_matches = []\n","        # Use the ratio_thresh that worked well for SIFT BFMatcher (0.75)\n","        for m, n in matches:\n","            if m.distance < 0.75 * n.distance:\n","                good_matches.append(m)\n","\n","        if self.debug and show_matches:\n","            # Draw only good matches for diagnostic\n","            img_matches = cv2.drawMatches(gray_missing_image, kp_missing_image, gray_complete_image, kp_complete_image, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","            plt.figure(figsize=(15, 8))\n","            plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))\n","            plt.title(\"Good Matches (BFMatcher with Ratio Test)\")\n","            plt.savefig('replacement_matching.png')\n","            plt.show()\n","\n","        if self.debug:\n","            print(f\"Total knn matches (before ratio test): {len(matches)}\")\n","            print(f\"Good matches used for transformation (after ratio test): {len(good_matches)}\")\n","\n","        if len(good_matches) < 4:\n","            raise ValueError(f\"Not enough good matches found to calculate transformation. Found: {len(good_matches)}\")\n","\n","        # Estimate affine transformation\n","        src_pts = np.float32([kp_missing_image[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n","        dst_pts = np.float32([kp_complete_image[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n","\n","        matrix, inliers = cv2.estimateAffinePartial2D(src_pts, dst_pts, method=cv2.RANSAC)\n","\n","        if matrix is None:\n","            raise ValueError(\"Transformation calculation failed. Images may be too dissimilar.\")\n","\n","        h1, w1 = complete_image.shape[:2]\n","        # Warp aligned_missing_image to align with complete_image's coordinate system\n","        aligned_missing_image = cv2.warpAffine(missing_image, matrix, (w1, h1), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0,0))\n","\n","        # Warp the white region mask to get its new aligned position\n","        aligned_white_mask = cv2.warpAffine(white_region_mask, matrix, (w1, h1), flags=cv2.INTER_NEAREST)\n","\n","        # --- Generate the output image containing only pixels from complete_image within the mask ---\n","        # Create a blank BGRA image (transparent)\n","        final_output = np.zeros_like(complete_image, dtype=np.uint8)\n","\n","        # Copy pixels from complete_image only where aligned_white_mask is 255\n","        # Set alpha channel to opaque for these copied pixels\n","        final_output[aligned_white_mask == 255] = complete_image[aligned_white_mask == 255]\n","        final_output[aligned_white_mask == 255, 3] = 255 # Ensure these pixels are opaque\n","\n","        # Optionally draw a sharp red outline around the aligned white region\n","        contours, _ = cv2.findContours(aligned_white_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","        if draw_contours:\n","            # Draw red outline, 1 pixel thick (BGRA: 0, 0, 255, 255 for red with full alpha)\n","            cv2.drawContours(final_output, contours, -1, (0, 0, 255, 255), thickness=1)\n","\n","        # --- SVG Contour Export ---\n","        if save_svg_contour:\n","            svg_filename = os.path.splitext(output_path)[0] + \"_contour.svg\"\n","            # Use explicit pixel units for size and correct (width, height) order\n","            dwg = svgwrite.Drawing(svg_filename, size=(f\"{w1}px\", f\"{h1}px\"), profile='tiny')\n","\n","            for contour in contours:\n","                # Reshape (N, 1, 2) contour to (N, 2) and convert to list of tuples\n","                points = contour.reshape(-1, 2).tolist()\n","                if len(points) > 1: # Polyline requires at least 2 points\n","                    dwg.add(dwg.polyline(points,\n","                                         stroke='black',\n","                                         fill='none',\n","                                         stroke_width='hairline'))\n","            dwg.save()\n","            if self.debug:\n","                print(f\"SVG contour saved to {svg_filename}\")\n","\n","        # Get DPI information from original complete image\n","        pil_complete_image_info = Image.open(complete_image_path).info\n","        dpi = pil_complete_image_info.get('dpi', (300, 300))\n","\n","        # Save the final output PNG\n","        final_pil = Image.fromarray(cv2.cvtColor(final_output, cv2.COLOR_BGRA2RGBA))\n","        final_pil.save(output_path, \"PNG\", dpi=dpi)\n","\n","        if save_intermediate:\n","            inter_path = os.path.splitext(output_path)[0] + \"_layers.tiff\"\n","            pil_complete_image = Image.fromarray(cv2.cvtColor(complete_image, cv2.COLOR_BGRA2RGBA))\n","            pil_missing_image = Image.fromarray(cv2.cvtColor(aligned_missing_image, cv2.COLOR_BGRA2RGBA))\n","            pil_contours = Image.fromarray(cv2.cvtColor(contours, cv2.COLOR_BGRA2RGBA))\n","            pil_final_output_layer = Image.fromarray(cv2.cvtColor(final_output, cv2.COLOR_BGRA2RGBA))\n","            pil_complete_image.save(inter_path, format=\"TIFF\", save_all=True, append_images=[pil_missing_image, pil_final_output_layer], dpi=dpi)\n","\n","        return complete_image, missing_image, final_output\n","\n","# ==========================================\n","# Colab Execution Example (Cleaned up)\n","# ========================================== # 1. Upload your images to the Colab files section (left menu).\n","# 2. Change the filenames below to match your uploaded files.\n","\n","if __name__ == \"__main__\":\n","    COMPLETE_IMAGE_PATH = \"complete.jpg\"  # Replace with your image 1 filename\n","    MISSING_IMAGE_PATH = \"missing.jpg\"     # Replace with your image 2 filename\n","    OUTPUT_PATH = \"replacement.png\"\n","\n","    # Initialize ImageAligner with default SIFT/BFMatcher\n","    # Set debug to True for diagnostic prints, False for production\n","    aligner = ImageAligner(debug=True)\n","\n","    try:\n","        # Check if files exist before running\n","        if os.path.exists(COMPLETE_IMAGE_PATH) and os.path.exists(MISSING_IMAGE_PATH):\n","            print(\"Processing images with SIFT/BFMatcher for alignment...\")\n","            # show_matches=True to display the feature matches visualization\n","            # draw_contours=True to draw a red 1px outline around the replaced region\n","            show_matches_option = True # Define a local variable for clarity\n","            complete_image, missing_image, final_output = aligner.process(COMPLETE_IMAGE_PATH,\n","                                                                          MISSING_IMAGE_PATH,\n","                                                                          OUTPUT_PATH,\n","                                                                          save_intermediate=True,\n","                                                                          show_matches=show_matches_option,\n","                                                                          draw_contours=False,\n","                                                                          save_svg_contour=True) # Enabled SVG export\n","\n","            if aligner.debug and show_matches_option:\n","                plt.figure(figsize=(10, 8))\n","                plt.imshow(cv2.cvtColor(final_output, cv2.COLOR_BGRA2RGBA))\n","                plt.title(\"Final Output Image\")\n","                plt.axis('off')\n","                plt.show()\n","\n","            print(f\"Success! Images processed. You can download '{OUTPUT_PATH}', '{os.path.splitext(OUTPUT_PATH)[0] + '_layers.tiff'}', and '{os.path.splitext(OUTPUT_PATH)[0] + '_contour.svg'}' from the files menu.\")\n","        else:\n","            print(\"Please upload your images and update the file paths in the script.\")\n","    except Exception as e:\n","        print(f\"Error: {str(e)}\")"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"lc_VnZUfA9iP","executionInfo":{"status":"error","timestamp":1771179709607,"user_tz":420,"elapsed":59,"user":{"displayName":"James Henriksen","userId":"05845938552738523524"}},"outputId":"5d35d7ee-222b-4f05-9a96-f13e493cf97f"},"source":["import cv2\n","import numpy as np\n","import os\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","import svgwrite # Added for SVG output\n","import argparse # Added for CLI functionality\n","\n","class ImageAligner:\n","    \"\"\"\n","    Library class for aligning images, isolating regions, and extracting composites.\n","    \"\"\"\n","    def __init__(self, debug=False, detector=None, matcher=None):\n","        self.debug = debug\n","\n","        # Initialize detector: SIFT as default as it worked well in tests\n","        if detector is None:\n","            self.detector = cv2.SIFT_create()\n","        else:\n","            self.detector = detector\n","\n","        # Initialize matcher: BFMatcher with NORM_L2 as default for SIFT\n","        if matcher is None:\n","            self.matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False) # crossCheck=False for knnMatch with ratio test\n","        else:\n","            self.matcher = matcher\n","\n","    def _find_white_region(self, img_bgra):\n","        \"\"\"\n","        Finds the largest white region, ignoring noise and damaged lines.\n","        Returns a binary mask of the white area.\n","        \"\"\"\n","        hsv = cv2.cvtColor(img_bgra, cv2.COLOR_BGRA2BGR)\n","        hsv = cv2.cvtColor(hsv, cv2.COLOR_BGR2HSV)\n","\n","        lower_white = np.array([0, 0, 200], dtype=np.uint8)\n","        upper_white = np.array([180, 50, 255], dtype=np.uint8)\n","        white_mask = cv2.inRange(hsv, lower_white, upper_white)\n","\n","        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n","        white_mask = cv2.morphologyEx(white_mask, cv2.MORPH_OPEN, kernel)\n","        white_mask = cv2.morphologyEx(white_mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n","\n","        contours, _ = cv2.findContours(white_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","        if not contours:\n","            raise ValueError(\"Could not find any white area in the second image.\")\n","\n","        largest_contour = max(contours, key=cv2.contourArea)\n","\n","        clean_mask = np.zeros_like(white_mask)\n","        cv2.drawContours(clean_mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n","\n","        return clean_mask\n","\n","    def _find_dark_lines_mask(self, img_bgra):\n","        \"\"\"\n","        Identifies continuous dark lines in a BGRA image and returns a binary mask.\n","        \"\"\"\n","        # Convert to grayscale\n","        gray = cv2.cvtColor(img_bgra, cv2.COLOR_BGRA2GRAY)\n","\n","        # Apply adaptive thresholding to identify dark regions\n","        thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n","                                       cv2.THRESH_BINARY_INV, 11, 2)\n","\n","        # Define a kernel for morphological operations\n","        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n","\n","        # Apply closing to connect close dark regions\n","        closed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)\n","        # Apply opening to remove small noisy areas\n","        opened = cv2.morphologyEx(closed, cv2.MORPH_OPEN, kernel)\n","\n","        # Find contours\n","        contours, _ = cv2.findContours(opened, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","\n","        # Create an empty mask to draw the significant dark lines\n","        dark_lines_mask = np.zeros_like(gray, dtype=np.uint8)\n","\n","        # Iterate through contours and filter by area, then draw\n","        min_contour_area = 50 # Adjust this value based on expected line thickness/size\n","        for contour in contours:\n","            if cv2.contourArea(contour) > min_contour_area:\n","                cv2.drawContours(dark_lines_mask, [contour], -1, 255, thickness=cv2.FILLED)\n","\n","        return dark_lines_mask\n","\n","    def process(self, complete_image_path, missing_image_path, output_path, save_intermediate=False, show_matches=False, draw_contours=False, save_svg_contour=False):\n","        \"\"\"\n","        Main pipeline function.\n","        \"\"\"\n","        complete_image = cv2.imread(complete_image_path, cv2.IMREAD_UNCHANGED)\n","        missing_image = cv2.imread(missing_image_path, cv2.IMREAD_UNCHANGED)\n","\n","        if complete_image is None or missing_image is None:\n","            raise FileNotFoundError(\"Could not load one or both input images. Check your file paths.\")\n","\n","        if complete_image.shape[2] == 3:\n","            complete_image = cv2.cvtColor(complete_image, cv2.COLOR_BGR2BGRA)\n","        if missing_image.shape[2] == 3:\n","            missing_image = cv2.cvtColor(missing_image, cv2.COLOR_BGR2BGRA)\n","\n","        if self.debug and show_matches:\n","            plt.figure(figsize=(20, 10))\n","\n","            plt.subplot(1, 2, 1)\n","            plt.imshow(cv2.cvtColor(complete_image, cv2.COLOR_BGRA2RGBA))\n","            plt.title(\"Complete Image (Original)\")\n","            plt.axis('off')\n","\n","            plt.subplot(1, 2, 2)\n","            plt.imshow(cv2.cvtColor(missing_image, cv2.COLOR_BGRA2RGBA))\n","            plt.title(\"Missing Image (Original)\")\n","            plt.axis('off')\n","            plt.show()\n","\n","        # Find white region in missing_image and make it transparent\n","        white_region_mask = self._find_white_region(missing_image)\n","        missing_image[white_region_mask == 255, 3] = 0\n","\n","        # Find dark lines in missing_image\n","        dark_lines_mask = self._find_dark_lines_mask(missing_image)\n","\n","        gray_complete_image = cv2.cvtColor(complete_image, cv2.COLOR_BGRA2GRAY)\n","        gray_missing_image = cv2.cvtColor(missing_image, cv2.COLOR_BGRA2GRAY)\n","\n","        # Create a valid mask for missing_image features: not transparent AND not dark lines\n","        valid_missing_image_mask = (missing_image[:, :, 3] > 0).astype(np.uint8) * 255\n","        valid_missing_image_mask = cv2.bitwise_and(valid_missing_image_mask, cv2.bitwise_not(dark_lines_mask))\n","\n","        # Feature detection\n","        kp_complete_image, des_complete_image = self.detector.detectAndCompute(gray_complete_image, None)\n","        kp_missing_image, des_missing_image = self.detector.detectAndCompute(gray_missing_image, mask=valid_missing_image_mask)\n","\n","        if self.debug:\n","            print(f\"Keypoints found in complete_image: {len(kp_complete_image) if kp_complete_image is not None else 0}\")\n","            print(f\"Keypoints found in missing_image (after masking): {len(kp_missing_image) if kp_missing_image is not None else 0}\")\n","\n","        if des_complete_image is None or des_missing_image is None or len(des_complete_image) < 4 or len(des_missing_image) < 4:\n","            raise ValueError(\"Not enough features found to align images. Check image content or mask parameters.\")\n","\n","        # Feature matching using knnMatch and ratio test\n","        matches = self.matcher.knnMatch(des_missing_image, des_complete_image, k=2)\n","\n","        good_matches = []\n","        # Use the ratio_thresh that worked well for SIFT BFMatcher (0.75)\n","        for m, n in matches:\n","            if m.distance < 0.75 * n.distance:\n","                good_matches.append(m)\n","\n","        if self.debug and show_matches:\n","            # Draw only good matches for diagnostic\n","            img_matches = cv2.drawMatches(gray_missing_image, kp_missing_image, gray_complete_image, kp_complete_image, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","            plt.figure(figsize=(15, 8))\n","            plt.imshow(cv2.cvtColor(img_matches, cv2.COLOR_BGR2RGB))\n","            plt.title(\"Good Matches (BFMatcher with Ratio Test)\")\n","            plt.savefig('replacement_matching.png')\n","            plt.show()\n","\n","        if self.debug:\n","            print(f\"Total knn matches (before ratio test): {len(matches)}\")\n","            print(f\"Good matches used for transformation (after ratio test): {len(good_matches)}\")\n","\n","        if len(good_matches) < 4:\n","            raise ValueError(f\"Not enough good matches found to calculate transformation. Found: {len(good_matches)}\")\n","\n","        # Estimate affine transformation\n","        src_pts = np.float32([kp_missing_image[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n","        dst_pts = np.float32([kp_complete_image[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n","\n","        matrix, inliers = cv2.estimateAffinePartial2D(src_pts, dst_pts, method=cv2.RANSAC)\n","\n","        if matrix is None:\n","            raise ValueError(\"Transformation calculation failed. Images may be too dissimilar.\")\n","\n","        h1, w1 = complete_image.shape[:2]\n","        # Warp aligned_missing_image to align with complete_image's coordinate system\n","        aligned_missing_image = cv2.warpAffine(missing_image, matrix, (w1, h1), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0,0,0,0))\n","\n","        # Warp the white region mask to get its new aligned position\n","        aligned_white_mask = cv2.warpAffine(white_region_mask, matrix, (w1, h1), flags=cv2.INTER_NEAREST)\n","\n","        # --- Generate the output image containing only pixels from complete_image within the mask ---\n","        # Create a blank BGRA image (transparent)\n","        final_output = np.zeros_like(complete_image, dtype=np.uint8)\n","\n","        # Copy pixels from complete_image only where aligned_white_mask is 255\n","        # Set alpha channel to opaque for these copied pixels\n","        final_output[aligned_white_mask == 255] = complete_image[aligned_white_mask == 255]\n","        final_output[aligned_white_mask == 255, 3] = 255 # Ensure these pixels are opaque\n","\n","        # Optionally draw a sharp red outline around the aligned white region\n","        contours, _ = cv2.findContours(aligned_white_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","        if draw_contours:\n","            # Draw red outline, 1 pixel thick (BGRA: 0, 0, 255, 255 for red with full alpha)\n","            cv2.drawContours(final_output, contours, -1, (0, 0, 255, 255), thickness=1)\n","\n","        # --- SVG Contour Export ---\n","        if save_svg_contour:\n","            svg_filename = os.path.splitext(output_path)[0] + \"_contour.svg\"\n","            # Use explicit pixel units for size and correct (width, height) order\n","            dwg = svgwrite.Drawing(svg_filename, size=(f\"{w1}px\", f\"{h1}px\"), profile='tiny')\n","\n","            # Simplify the contour using approxPolyDP\n","            # We use the contours found above, which are already from aligned_white_mask and CHAIN_APPROX_NONE\n","            for contour in contours:\n","                epsilon = 0.005 * cv2.arcLength(contour, True) # 0.5% of arc length\n","                approx_contour = cv2.approxPolyDP(contour, epsilon, True)\n","\n","                # Reshape (N, 1, 2) contour to (N, 2) and convert to list of tuples\n","                points = approx_contour.reshape(-1, 2).tolist()\n","                if len(points) > 1: # Polyline requires at least 2 points\n","                    path_data = f\"M {points[0][0]},{points[0][1]}\"\n","                    for p in points[1:]:\n","                        path_data += f\" L {p[0]},{p[1]}\"\n","                    path_data += \" Z\" # Close the path\n","                    dwg.add(dwg.path(d=path_data,\n","                                     stroke='black',\n","                                     fill='none',\n","                                     stroke_width='hairline'))\n","            dwg.save()\n","            if self.debug:\n","                print(f\"SVG contour saved to {svg_filename}\")\n","\n","        # Get DPI information from original complete image\n","        pil_complete_image_info = Image.open(complete_image_path).info\n","        dpi = pil_complete_image_info.get('dpi', (300, 300))\n","\n","        # Save the final output PNG\n","        final_pil = Image.fromarray(cv2.cvtColor(final_output, cv2.COLOR_BGRA2RGBA))\n","        final_pil.save(output_path, \"PNG\", dpi=dpi)\n","\n","        if save_intermediate:\n","            inter_path = os.path.splitext(output_path)[0] + \"_layers.tiff\"\n","            pil_complete_image = Image.fromarray(cv2.cvtColor(complete_image, cv2.COLOR_BGRA2RGBA))\n","            pil_missing_image = Image.fromarray(cv2.cvtColor(aligned_missing_image, cv2.COLOR_BGRA2RGBA))\n","            # Add the new final_output as the third layer (making it the 4th layer overall)\n","            pil_final_output_layer = Image.fromarray(cv2.cvtColor(final_output, cv2.COLOR_BGRA2RGBA))\n","            pil_complete_image.save(inter_path, format=\"TIFF\", save_all=True, append_images=[pil_missing_image, pil_final_output_layer], dpi=dpi)\n","\n","        return complete_image, missing_image, final_output\n","\n","# ========================================== # Added main function for CLI\n","def main():\n","    parser = argparse.ArgumentParser(description='Align two images, replacing a white region in the second with a part of the first.')\n","    parser.add_argument('complete_image_path', type=str, help='Path to the complete image (Image 1).')\n","    parser.add_argument('missing_image_path', type=str, help='Path to the missing image (Image 2).')\n","    parser.add_argument('output_path', type=str, help='Path to save the final output image (e.g., replacement.png).')\n","    parser.add_argument('--save_intermediate', action='store_true', help='Save intermediate aligned images in a multi-layer TIFF format.')\n","    parser.add_argument('--show_matches', action='store_true', help='Display feature matching visualization using matplotlib.')\n","    parser.add_argument('--draw_contours', action='store_true', help='Draw a red 1px outline around the replaced region in the final output.')\n","    parser.add_argument('--save_svg_contour', action='store_true', help='Save the aligned contour of the white region as an SVG file.')\n","    parser.add_argument('--debug', action='store_true', help='Enable debug prints for diagnostic information.')\n","\n","    args = parser.parse_args()\n","\n","    aligner = ImageAligner(debug=args.debug) # Pass debug argument to ImageAligner\n","\n","    try:\n","        # Check if files exist before running\n","        if os.path.exists(args.complete_image_path) and os.path.exists(args.missing_image_path):\n","            print(\"Processing images with SIFT/BFMatcher for alignment...\")\n","            complete_image, missing_image, final_output = aligner.process(\n","                args.complete_image_path,\n","                args.missing_image_path,\n","                args.output_path,\n","                save_intermediate=args.save_intermediate,\n","                show_matches=args.show_matches,\n","                draw_contours=args.draw_contours,\n","                save_svg_contour=args.save_svg_contour\n","            )\n","\n","            if aligner.debug and args.show_matches:\n","                plt.figure(figsize=(10, 8))\n","                plt.imshow(cv2.cvtColor(final_output, cv2.COLOR_BGRA2RGBA))\n","                plt.title(\"Final Output Image\")\n","                plt.axis('off')\n","                plt.show()\n","\n","            outputs = [f\"'{args.output_path}'\"]\n","            if args.save_intermediate:\n","                outputs.append(f\"'{os.path.splitext(args.output_path)[0] + '_layers.tiff'}'\")\n","            if args.save_svg_contour:\n","                outputs.append(f\"'{os.path.splitext(args.output_path)[0] + '_contour.svg'}'\")\n","\n","            print(f\"Success! Images processed. You can download {', '.join(outputs)} from the files menu.\")\n","        else:\n","            print(\"Please ensure both input image files exist at the specified paths.\")\n","    except Exception as e:\n","        print(f\"Error: {str(e)}\")\n","\n","if __name__ == \"__main__\":\n","    main()\n"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["usage: colab_kernel_launcher.py [-h] [--save_intermediate] [--show_matches]\n","                                [--draw_contours] [--save_svg_contour]\n","                                [--debug]\n","                                complete_image_path missing_image_path\n","                                output_path\n","colab_kernel_launcher.py: error: the following arguments are required: missing_image_path, output_path\n","ERROR:root:Internal Python error in the inspect module.\n","Below is the traceback from this internal error.\n","\n"]},{"output_type":"stream","name":"stdout","text":["Traceback (most recent call last):\n","  File \"/usr/lib/python3.12/argparse.py\", line 1943, in _parse_known_args2\n","    namespace, args = self._parse_known_args(args, namespace, intermixed)\n","                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/argparse.py\", line 2230, in _parse_known_args\n","    raise ArgumentError(None, _('the following arguments are required: %s') %\n","argparse.ArgumentError: the following arguments are required: missing_image_path, output_path\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"/tmp/ipython-input-1347178740.py\", line 293, in <cell line: 0>\n","    main()\n","  File \"/tmp/ipython-input-1347178740.py\", line 255, in main\n","    args = parser.parse_args()\n","           ^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/argparse.py\", line 1904, in parse_args\n","    args, argv = self.parse_known_args(args, namespace)\n","                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/argparse.py\", line 1914, in parse_known_args\n","    return self._parse_known_args2(args, namespace, intermixed=False)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/argparse.py\", line 1945, in _parse_known_args2\n","    self.error(str(err))\n","  File \"/usr/lib/python3.12/argparse.py\", line 2650, in error\n","    self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)\n","  File \"/usr/lib/python3.12/argparse.py\", line 2637, in exit\n","    _sys.exit(status)\n","SystemExit: 2\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n","    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n","           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n","    return f(*args, **kwargs)\n","           ^^^^^^^^^^^^^^^^^^\n","  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n","    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n","                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/inspect.py\", line 1769, in getinnerframes\n","    traceback_info = getframeinfo(tb, context)\n","                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n","  File \"/usr/lib/python3.12/inspect.py\", line 1701, in getframeinfo\n","    lineno = frame.f_lineno\n","             ^^^^^^^^^^^^^^\n","AttributeError: 'tuple' object has no attribute 'f_lineno'\n"]},{"output_type":"error","ename":"TypeError","evalue":"object of type 'NoneType' has no len()","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m/usr/lib/python3.12/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args2\u001b[0;34m(self, args, namespace, intermixed)\u001b[0m\n\u001b[1;32m   1942\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1943\u001b[0;31m                 \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermixed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1944\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args\u001b[0;34m(self, arg_strings, namespace, intermixed)\u001b[0m\n\u001b[1;32m   2229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequired_actions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2230\u001b[0;31m             raise ArgumentError(None, _('the following arguments are required: %s') %\n\u001b[0m\u001b[1;32m   2231\u001b[0m                        ', '.join(required_actions))\n","\u001b[0;31mArgumentError\u001b[0m: the following arguments are required: missing_image_path, output_path","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-1347178740.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-1347178740.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m     \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/argparse.py\u001b[0m in \u001b[0;36mparse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1903\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1904\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1905\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/argparse.py\u001b[0m in \u001b[0;36mparse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1913\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse_known_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_known_args2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermixed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/argparse.py\u001b[0m in \u001b[0;36m_parse_known_args2\u001b[0;34m(self, args, namespace, intermixed)\u001b[0m\n\u001b[1;32m   1944\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1945\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1946\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.12/argparse.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'prog'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'message'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2650\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%(prog)s: error: %(message)s\\n'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/lib/python3.12/argparse.py\u001b[0m in \u001b[0;36mexit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2636\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2637\u001b[0;31m         \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mSystemExit\u001b[0m: 2","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"]}]}]}